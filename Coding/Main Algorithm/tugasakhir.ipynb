{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported to similar_listings_4509.json\n",
      "Listing:\n",
      "title                        Take over/Over Kredit Rumah Kavling\n",
      "facilities                                                      \n",
      "description    ['cicilan 2jt flat sisa 54bulan', 'akses jalan...\n",
      "Name: 5000, dtype: object\n",
      "\n",
      "Top 5 similar listings:\n",
      "                                                  title  \\\n",
      "4512        RUMAH SIAP HUNI DI GRAND WISATA KOTA BEKASI   \n",
      "4564  DI JUAL CEPAT RUMAH BARU RENOVASI DI GRAND WIS...   \n",
      "4758  Dijual Cepat Rumah Full Renovasi di Grand Wisa...   \n",
      "4710  Di jual rumah mewah grand wisata kota bekasi a...   \n",
      "4799  DIJUAL RUMAH FULL RENOV 2 LANTAI 6 KAMAR GRAND...   \n",
      "4371    DI JUAL RUMAH DALAM CLUSTER GRAND WISATA BEKASI   \n",
      "4382  DI JUAL RUMAH SIAP HUNI 2 LANTAI DI GRAND WISA...   \n",
      "4700         Grand Wisata Rumah Siap Huni Di Jual Cepat   \n",
      "4742  Grand Wisata Rumah Siap Huni Di Jual Cepat 2.5...   \n",
      "4696         Grand Wisata Rumah Siap Huni Di Jual Cepat   \n",
      "\n",
      "                                             facilities  \\\n",
      "4512    ['ac', 'carport', 'garden', 'pam', 'telephone']   \n",
      "4564  ['ac', 'carport', 'garden', 'pam', 'telephone'...   \n",
      "4758    ['ac', 'carport', 'garden', 'pam', 'telephone']   \n",
      "4710  ['ac', 'carport', 'garden', 'pam', 'refrigerat...   \n",
      "4799  ['carport', 'garden', 'fire extenguisher', 'pa...   \n",
      "4371  ['garden', 'carport', 'pam', 'telephone', 'swi...   \n",
      "4382    ['ac', 'carport', 'garden', 'pam', 'telephone']   \n",
      "4700                    ['carport', 'garasi', 'garden']   \n",
      "4742             ['carport', 'garasi', 'garden', 'pam']   \n",
      "4696                              ['carport', 'garasi']   \n",
      "\n",
      "                                            description  \n",
      "4512  ['di jual rumah mewah', 'grand wisata cluster ...  \n",
      "4564  ['di jual rumah mewah', 'grand wisata cluster ...  \n",
      "4758  ['di jual rumah mewah', 'grand wisata cluster ...  \n",
      "4710  ['di jual rumah mewah', 'grand wisata cluster ...  \n",
      "4799  ['di jual rumah mewah', 'grand wisata cluster ...  \n",
      "4371  ['di jual rumah mewah', 'grand wisata cluster ...  \n",
      "4382  ['di jual rumah mewah', 'grand wisata', 'fasil...  \n",
      "4700  ['di jual rumah siap huni di grand wisata deng...  \n",
      "4742  ['di jual rumah siap huni di grand wisata deng...  \n",
      "4696  ['di jual rumah siap huni di grand wisata deng...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load the dataset\n",
    "df = pd.read_csv('updated_jabodetabeksur_olx_housing_dataset_.csv')\n",
    "\n",
    "# 2. Preprocess descriptions (lowercase & fillna)\n",
    "df['description'] = df['description'].fillna('').str.lower()\n",
    "df['facilities'] = df['facilities'].fillna('').str.lower()\n",
    "df['combined_text'] = df['description'] + ' ' + df['facilities']\n",
    "\n",
    "# 3. TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "tfidf_matrix = vectorizer.fit_transform(df['combined_text'])\n",
    "\n",
    "# 4. Cosine similarity calculation\n",
    "cosine_sim_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# 5. Function to get top-N similar properties\n",
    "def export_similar_properties(property_index, top_n=5, file_format='json'):\n",
    "    sim_scores = list(enumerate(cosine_sim_matrix[property_index]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    top_indices = [i for i, score in sim_scores[1:top_n+1]]  # skip itself\n",
    "    \n",
    "    results = df.iloc[top_indices][['title', 'facilities', 'description']].copy()\n",
    "    results['similarity_score'] = [sim_scores[i+1][1] for i in range(top_n)]  # add scores\n",
    "    \n",
    "    # Export\n",
    "    if file_format == 'csv':\n",
    "        results.to_csv(f'similar_listings_{property_index}.csv', index=False)\n",
    "        print(f'Exported to similar_listings_{property_index}.csv')\n",
    "    elif file_format == 'json':\n",
    "        results.to_json(f'similar_listings_{property_index}.json', orient='records', indent=2)\n",
    "        print(f'Exported to similar_listings_{property_index}.json')\n",
    "    else:\n",
    "        print(\"Unsupported format. Use 'csv' or 'json'.\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage: get top 5 similar properties to listing at index 0\n",
    "similar_props = export_similar_properties(4509, top_n=10)\n",
    "print(\"Listing:\")\n",
    "print(df.iloc[5000][['title', 'facilities', 'description']])\n",
    "print(\"\\nTop 5 similar listings:\")\n",
    "print(similar_props[['title', 'facilities', 'description']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\ops\\array_ops.py:218\u001b[39m, in \u001b[36m_na_arithmetic_op\u001b[39m\u001b[34m(left, right, op, is_cmp)\u001b[39m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\computation\\expressions.py:242\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(op, a, b, use_numexpr)\u001b[39m\n\u001b[32m    240\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[32m    241\u001b[39m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\computation\\expressions.py:73\u001b[39m, in \u001b[36m_evaluate_standard\u001b[39m\u001b[34m(op, op_str, a, b)\u001b[39m\n\u001b[32m     72\u001b[39m     _store_test_result(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: can only concatenate str (not \"int\") to str",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mTRANSPORT\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mTRANSPORT\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     18\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mWORSHIP\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mWORSHIP\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mcombined_text\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdescription\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfacilities\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSCHOOL\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m + \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m + df[\u001b[33m'\u001b[39m\u001b[33mUNIVERSITY\u001b[39m\u001b[33m'\u001b[39m] + \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m + df [\u001b[33m'\u001b[39m\u001b[33mHOSPITAL\u001b[39m\u001b[33m'\u001b[39m] + \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m + df[\u001b[33m'\u001b[39m\u001b[33mMALL\u001b[39m\u001b[33m'\u001b[39m] + \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m + df[\u001b[33m'\u001b[39m\u001b[33mMARKET\u001b[39m\u001b[33m'\u001b[39m] + \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m + df[\u001b[33m'\u001b[39m\u001b[33mTRANSPORT\u001b[39m\u001b[33m'\u001b[39m] + \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m + df[\u001b[33m'\u001b[39m\u001b[33mWORSHIP\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# 3. TF-IDF Vectorization\u001b[39;00m\n\u001b[32m     22\u001b[39m vectorizer = TfidfVectorizer(max_features=\u001b[32m5000\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[39m, in \u001b[36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     72\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m     74\u001b[39m other = item_from_zerodim(other)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\arraylike.py:186\u001b[39m, in \u001b[36mOpsMixin.__add__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m__add__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__add__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m    100\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    101\u001b[39m \u001b[33;03m    Get Addition of DataFrame and other, column-wise.\u001b[39;00m\n\u001b[32m    102\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    184\u001b[39m \u001b[33;03m    moose     3.0     NaN\u001b[39;00m\n\u001b[32m    185\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\series.py:6135\u001b[39m, in \u001b[36mSeries._arith_method\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m   6133\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[32m   6134\u001b[39m     \u001b[38;5;28mself\u001b[39m, other = \u001b[38;5;28mself\u001b[39m._align_for_op(other)\n\u001b[32m-> \u001b[39m\u001b[32m6135\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase\u001b[49m\u001b[43m.\u001b[49m\u001b[43mIndexOpsMixin\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\base.py:1382\u001b[39m, in \u001b[36mIndexOpsMixin._arith_method\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m   1379\u001b[39m     rvalues = np.arange(rvalues.start, rvalues.stop, rvalues.step)\n\u001b[32m   1381\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m np.errstate(\u001b[38;5;28mall\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1382\u001b[39m     result = \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43marithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._construct_result(result, name=res_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\ops\\array_ops.py:283\u001b[39m, in \u001b[36marithmetic_op\u001b[39m\u001b[34m(left, right, op)\u001b[39m\n\u001b[32m    279\u001b[39m     _bool_arith_check(op, left, right)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    281\u001b[39m     \u001b[38;5;66;03m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[32m    282\u001b[39m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m     res_values = \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\ops\\array_ops.py:227\u001b[39m, in \u001b[36m_na_arithmetic_op\u001b[39m\u001b[34m(left, right, op, is_cmp)\u001b[39m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    220\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[32m    221\u001b[39m         left.dtype == \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(right, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mobject\u001b[39m\n\u001b[32m    222\u001b[39m     ):\n\u001b[32m   (...)\u001b[39m\u001b[32m    225\u001b[39m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[32m    226\u001b[39m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m         result = \u001b[43m_masked_arith_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    228\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    229\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\ops\\array_ops.py:163\u001b[39m, in \u001b[36m_masked_arith_op\u001b[39m\u001b[34m(x, y, op)\u001b[39m\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# See GH#5284, GH#5035, GH#19448 for historical reference\u001b[39;00m\n\u001b[32m    162\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m         result[mask] = \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxrav\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myrav\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(y):\n",
      "\u001b[31mTypeError\u001b[39m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load the dataset\n",
    "df = pd.read_csv('housing_with_entities.csv')\n",
    "\n",
    "# 2. Preprocess descriptions (lowercase & fillna)\n",
    "df['description'] = df['description'].fillna('').str.lower()\n",
    "df['facilities'] = df['facilities'].fillna('').str.lower()\n",
    "df['SCHOOL'] = df['SCHOOL']\n",
    "df['UNIVERSITY'] = df['UNIVERSITY']\n",
    "df['HOSPITAL'] = df['HOSPITAL']\n",
    "df['MALL'] = df['MALL']\n",
    "df['MARKET'] = df['MARKET']\n",
    "df['TRANSPORT'] = df['TRANSPORT']\n",
    "df['WORSHIP'] = df['WORSHIP']\n",
    "df['combined_text'] = df['description'] + ' ' + df['facilities'] + ' ' + df['SCHOOL'] + ' ' + df['UNIVERSITY'] + ' ' + df ['HOSPITAL'] + ' ' + df['MALL'] + ' ' + df['MARKET'] + ' ' + df['TRANSPORT'] + ' ' + df['WORSHIP']\n",
    "\n",
    "# 3. TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "tfidf_matrix = vectorizer.fit_transform(df['combined_text'])\n",
    "\n",
    "# 4. Cosine similarity calculation\n",
    "cosine_sim_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# 5. Function to get top-N similar properties\n",
    "def export_similar_properties(property_index, top_n=5, file_format='json'):\n",
    "    sim_scores = list(enumerate(cosine_sim_matrix[property_index]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    top_indices = [i for i, score in sim_scores[1:top_n+1]]  # skip itself\n",
    "    \n",
    "    results = df.iloc[top_indices][['title', 'facilities', 'description']].copy()\n",
    "    results['similarity_score'] = [sim_scores[i+1][1] for i in range(top_n)]  # add scores\n",
    "    \n",
    "    # Export\n",
    "    if file_format == 'csv':\n",
    "        results.to_csv(f'similar_listings_{property_index}.csv', index=False)\n",
    "        print(f'Exported to similar_listings_{property_index}.csv')\n",
    "    elif file_format == 'json':\n",
    "        results.to_json(f'similar_listings_{property_index}.json', orient='records', indent=2)\n",
    "        print(f'Exported to similar_listings_{property_index}.json')\n",
    "    else:\n",
    "        print(\"Unsupported format. Use 'csv' or 'json'.\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage: get top 5 similar properties to listing at index 0\n",
    "similar_props = export_similar_properties(4509, top_n=10)\n",
    "print(\"Listing:\")\n",
    "print(df.iloc[5000][['title', 'facilities', 'description']])\n",
    "print(\"\\nTop 5 similar listings:\")\n",
    "print(similar_props[['title', 'facilities', 'description']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported to similar_listings_4509.json\n",
      "Listing:\n",
      "title                        Take over/Over Kredit Rumah Kavling\n",
      "description    ['cicilan 2jt flat sisa 54bulan', 'akses jalan...\n",
      "Name: 5000, dtype: object\n",
      "\n",
      "Top 5 similar listings:\n",
      "                                                  title  \\\n",
      "4512        RUMAH SIAP HUNI DI GRAND WISATA KOTA BEKASI   \n",
      "4758  Dijual Cepat Rumah Full Renovasi di Grand Wisa...   \n",
      "4564  DI JUAL CEPAT RUMAH BARU RENOVASI DI GRAND WIS...   \n",
      "4799  DIJUAL RUMAH FULL RENOV 2 LANTAI 6 KAMAR GRAND...   \n",
      "4710  Di jual rumah mewah grand wisata kota bekasi a...   \n",
      "4371    DI JUAL RUMAH DALAM CLUSTER GRAND WISATA BEKASI   \n",
      "4382  DI JUAL RUMAH SIAP HUNI 2 LANTAI DI GRAND WISA...   \n",
      "4700         Grand Wisata Rumah Siap Huni Di Jual Cepat   \n",
      "4696         Grand Wisata Rumah Siap Huni Di Jual Cepat   \n",
      "4695        Grand Wisata Rumah Di Jual Posisi Boulevard   \n",
      "\n",
      "                                            description  \n",
      "4512  ['di jual rumah mewah', 'grand wisata cluster ...  \n",
      "4758  ['di jual rumah mewah', 'grand wisata cluster ...  \n",
      "4564  ['di jual rumah mewah', 'grand wisata cluster ...  \n",
      "4799  ['di jual rumah mewah', 'grand wisata cluster ...  \n",
      "4710  ['di jual rumah mewah', 'grand wisata cluster ...  \n",
      "4371  ['di jual rumah mewah', 'grand wisata cluster ...  \n",
      "4382  ['di jual rumah mewah', 'grand wisata', 'fasil...  \n",
      "4700  ['di jual rumah siap huni di grand wisata deng...  \n",
      "4696  ['di jual rumah siap huni di grand wisata deng...  \n",
      "4695  ['di jual rumah siap huni di grand wisata deng...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load the dataset\n",
    "df = pd.read_csv('updated_jabodetabeksur_olx_housing_dataset_.csv')\n",
    "\n",
    "# 2. Preprocess descriptions (lowercase & fillna)\n",
    "df['description'] = df['description'].fillna('').str.lower()\n",
    "\n",
    "# 3. TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "tfidf_matrix = vectorizer.fit_transform(df['description'])\n",
    "\n",
    "# 4. Cosine similarity calculation\n",
    "cosine_sim_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# 5. Function to get top-N similar properties\n",
    "def export_similar_properties(property_index, top_n=5, file_format='json'):\n",
    "    sim_scores = list(enumerate(cosine_sim_matrix[property_index]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    top_indices = [i for i, score in sim_scores[1:top_n+1]]  # skip itself\n",
    "    \n",
    "    results = df.iloc[top_indices][['title', 'description']].copy()\n",
    "    results['similarity_score'] = [sim_scores[i+1][1] for i in range(top_n)]  # add scores\n",
    "    \n",
    "    # Export\n",
    "    if file_format == 'csv':\n",
    "        results.to_csv(f'similar_listings_{property_index}.csv', index=False)\n",
    "        print(f'Exported to similar_listings_{property_index}.csv')\n",
    "    elif file_format == 'json':\n",
    "        results.to_json(f'similar_listings_{property_index}_nofacilities.json', orient='records', indent=2)\n",
    "        print(f'Exported to similar_listings_{property_index}.json')\n",
    "    else:\n",
    "        print(\"Unsupported format. Use 'csv' or 'json'.\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage: get top 5 similar properties to listing at index 0\n",
    "similar_props = export_similar_properties(4509, top_n=10)\n",
    "print(\"Listing:\")\n",
    "print(df.iloc[5000][['title', 'description']])\n",
    "print(\"\\nTop 5 similar listings:\")\n",
    "print(similar_props[['title', 'description']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (1976635297.py, line 9)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mold_df = pd.read_csv(\"C:\\Users\\madea\\OneDrive\\Documents\\Kuliah\\Semester 8\\Tugas Akhir\\Coding\\Data Preprocessing\\updated_jabodetabeksur_olx_housing_dataset_.csv\")\u001b[39m\n                                                                                                                                                                    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.sparse import hstack\n",
    "import numpy as np\n",
    "\n",
    "# Load both datasets\n",
    "old_df = pd.read_csv(\"C:\\Users\\madea\\OneDrive\\Documents\\Kuliah\\Semester 8\\Tugas Akhir\\Coding\\Data Preprocessing\\updated_jabodetabeksur_olx_housing_dataset_.csv\")\n",
    "new_df = pd.read_csv(\"housing_with_entities.csv\")\n",
    "\n",
    "# Preprocess both datasets\n",
    "def preprocess(df):\n",
    "    df['description'] = df['description'].fillna('').str.lower()\n",
    "    df['facilities'] = df['facilities'].fillna('').str.lower()\n",
    "    df['combined_text'] = df['description'] + ' ' + df['facilities']\n",
    "    return df\n",
    "\n",
    "old_df = preprocess(old_df)\n",
    "new_df = preprocess(new_df)\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "old_tfidf = vectorizer.fit_transform(old_df['combined_text'])\n",
    "new_tfidf = vectorizer.transform(new_df['combined_text'])  # use same vocab\n",
    "\n",
    "# Normalize entity features for new_df\n",
    "entity_features = ['SCHOOL', 'UNIVERSITY', 'HOSPITAL', 'MALL', 'MARKET', 'TRANSPORT', 'WORSHIP']\n",
    "new_structured = new_df[entity_features].fillna(0).astype(int)\n",
    "scaler = MinMaxScaler()\n",
    "new_structured_scaled = scaler.fit_transform(new_structured)\n",
    "\n",
    "# Combine TF-IDF and structured features\n",
    "from scipy.sparse import csr_matrix\n",
    "combined_matrix = hstack([new_tfidf, csr_matrix(new_structured_scaled)])\n",
    "\n",
    "# Compute cosine similarity\n",
    "old_sim_matrix = cosine_similarity(old_tfidf)\n",
    "new_sim_matrix = cosine_similarity(combined_matrix)\n",
    "\n",
    "# Comparison Function\n",
    "def compare_recommendations(property_index, top_n=5):\n",
    "    print(f\"\\n📌 Property Index: {property_index}\\n\")\n",
    "    \n",
    "    # Get similarity scores\n",
    "    old_scores = list(enumerate(old_sim_matrix[property_index]))\n",
    "    new_scores = list(enumerate(new_sim_matrix[property_index]))\n",
    "\n",
    "    # Sort and remove self\n",
    "    old_top = sorted(old_scores, key=lambda x: x[1], reverse=True)[1:top_n+1]\n",
    "    new_top = sorted(new_scores, key=lambda x: x[1], reverse=True)[1:top_n+1]\n",
    "\n",
    "    # Display comparison\n",
    "    print(\"🔷 Top Recommendations from OLD Dataset:\")\n",
    "    for i, score in old_top:\n",
    "        print(f\"- {old_df.iloc[i]['title']} (Score: {score:.4f})\")\n",
    "\n",
    "    print(\"\\n🟢 Top Recommendations from NEW Dataset:\")\n",
    "    for i, score in new_top:\n",
    "        print(f\"- {new_df.iloc[i]['title']} (Score: {score:.4f})\")\n",
    "\n",
    "# Example: Compare top 5 recommendations for property at index 1000\n",
    "compare_recommendations(property_index=1000, top_n=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
