{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e411ebc0",
   "metadata": {},
   "source": [
    "### Library Usage in Hybrid Recommender Systems for Property Market\n",
    "\n",
    "This notebook utilizes several powerful Python libraries to build a **Hybrid Recommender System** that combines a Knowledge Based Recommender System (KBRS), a Content Based Recommender System (CBRS), and Profile Matching for property recommendations. Hereâ€™s how each library contributes:\n",
    "\n",
    "- **pandas**: Used for data manipulation and analysis, especially for loading, cleaning, and transforming property datasets.\n",
    "- **numpy**: Provides efficient numerical operations, particularly useful for handling arrays and numerical computations in feature engineering and similarity calculations.\n",
    "- **spacy**: Enables advanced Natural Language Processing (NLP) for extracting entities (like schools, hospitals, malls) from property descriptions, enriching the dataset with contextual features.\n",
    "- **pathlib**: Simplifies file and directory operations, making it easy to manage paths for reading and saving datasets and results.\n",
    "- **rapidfuzz**: Offers fast fuzzy string matching, which helps in identifying relevant entities in property descriptions even when there are typos or variations in wording.\n",
    "- **sklearn.preprocessing (MinMaxScaler, OneHotEncoder)**: Used for feature scaling and encoding categorical variables, ensuring that structured property features are normalized and machine-readable for similarity computations.\n",
    "- **sklearn.metrics.pairwise (cosine_similarity)**: Calculates similarity scores between user preferences and property features, forming the core of the CBRS.\n",
    "- **scipy.sparse (csr_matrix, hstack)**: Efficiently handles large, sparse feature matrices, which is crucial when combining one-hot encoded and scaled features for similarity calculations.\n",
    "\n",
    "By integrating these libraries, the system can:\n",
    "- Extract and encode both structured and unstructured property features,\n",
    "- Match properties to user personas (KBRS),\n",
    "- Compute similarity between user preferences and property listings (CBRS),\n",
    "- Apply profile matching to rank recommendations based on how closely they fit the user's ideal profile.\n",
    "\n",
    "This hybrid approach leverages both domain knowledge and data-driven insights to deliver more accurate and personalized property recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140d2000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from pathlib import Path\n",
    "from rapidfuzz import fuzz\n",
    "from spacy.pipeline import EntityRuler\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix, hstack\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ad81e8",
   "metadata": {},
   "source": [
    "## Iner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd05f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load your dataset\n",
    "df = pd.read_csv(r'C:\\Users\\madea\\OneDrive\\Documents\\Kuliah\\Semester 8\\Tugas Akhir\\Coding\\Data Preprocessing\\updated_jabodetabeksur_olx_housing_dataset_.csv')\n",
    "df['description'] = df['description'].fillna('').str.lower()\n",
    "\n",
    "# 2. Define entity patterns\n",
    "entity_patterns = {\n",
    "    \"SCHOOL\": [\"sd\", \"smp\", \"sma\", \"sekolah\", \"tk\", \"playgroup\"],\n",
    "    \"UNIVERSITY\": [\"universitas\", \"kampus\", \"perguruan tinggi\"],\n",
    "    \"HOSPITAL\": [\"rumah sakit\", \"rs\"],\n",
    "    \"MALL\": [\"mall\", \"plaza\", \"supermall\", \"pusat perbelanjaan\"],\n",
    "    \"MARKET\": [\"pasar\", \"market\", \"traditional market\"],\n",
    "    \"TRANSPORT\": [\"terminal\", \"stasiun\", \"halte\", \"tol\", \"bandara\"],\n",
    "    \"WORSHIP\": [\"masjid\", \"gereja\", \"pura\"]\n",
    "}\n",
    "\n",
    "# 3. Initialize spaCy with a blank Indonesian model\n",
    "nlp = spacy.blank('id')\n",
    "ruler = nlp.add_pipe('entity_ruler')\n",
    "\n",
    "# 4. Add patterns to EntityRuler\n",
    "patterns = []\n",
    "for label, keywords in entity_patterns.items():\n",
    "    for word in keywords:\n",
    "        patterns.append({\"label\": label, \"pattern\": word})\n",
    "ruler.add_patterns(patterns)\n",
    "\n",
    "# 5. Fuzzy matcher fallback\n",
    "def fuzzy_match(text, keywords, threshold=85):\n",
    "    return any(fuzz.partial_ratio(text, k) >= threshold for k in keywords)\n",
    "\n",
    "# 6. Entity extraction function\n",
    "def extract_entities(description):\n",
    "    doc = nlp(description)\n",
    "    found_entities = {label: 0 for label in entity_patterns.keys()}\n",
    "\n",
    "    # Exact rule-based matches\n",
    "    for ent in doc.ents:\n",
    "        found_entities[ent.label_] = 1\n",
    "\n",
    "    # Fuzzy fallback check\n",
    "    for label, keywords in entity_patterns.items():\n",
    "        if found_entities[label] == 0:\n",
    "            if fuzzy_match(description, keywords):\n",
    "                found_entities[label] = 1\n",
    "\n",
    "    return found_entities\n",
    "\n",
    "# 7. Apply to dataset and expand columns\n",
    "entity_df = df['description'].apply(extract_entities).apply(pd.Series)\n",
    "df = pd.concat([df, entity_df], axis=1)\n",
    "\n",
    "\n",
    "# Export results to CSV\n",
    "filepath_csv = Path('INER/dataset_with_entities.csv')  \n",
    "filepath_csv.parent.mkdir(parents=True, exist_ok=True)  \n",
    "df.to_csv(filepath_csv, index=False, encoding='utf-8-sig')\n",
    "\n",
    "# Export results to JSON\n",
    "filepath_json = Path('INER/dataset_with_entities.json')  \n",
    "filepath_json.parent.mkdir(parents=True, exist_ok=True)  \n",
    "df.to_json(filepath_json, orient='records', force_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa87735a",
   "metadata": {},
   "source": [
    "# Labeling KBRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6ebba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('INER/dataset_with_entities.csv')\n",
    "\n",
    "# Define ideal profiles for each persona\n",
    "ideal_personas = {\n",
    "    \"Pasangan Bekerja dengan Anak\": {\n",
    "        \"type\": \"Rumah\",\n",
    "        \"land_area\": (200, 600),\n",
    "        \"building_area\": (200, 600),\n",
    "        \"bedrooms\": [3],\n",
    "        \"bathrooms\": [2],\n",
    "        \"SCHOOL\": 1,\n",
    "        \"HOSPITAL\": 1,\n",
    "        \"TRANSPORT\": 1,\n",
    "        \"MARKET\": 1\n",
    "    },\n",
    "    \"Pasangan Bekerja tanpa Anak\": {\n",
    "        \"type\": [\"Apartemen\", \"Rumah\"],\n",
    "        \"land_area\": (22, 70),\n",
    "        \"building_area\": (22, 70),\n",
    "        \"bedrooms\": [2],\n",
    "        \"bathrooms\": [2],\n",
    "        \"MALL\": 1,\n",
    "        \"TRANSPORT\": 1\n",
    "    },\n",
    "    \"Individu Lajang\": {\n",
    "        \"type\": \"Apartemen\",\n",
    "        \"land_area\": (22, 50),\n",
    "        \"building_area\": (22, 50),\n",
    "        \"bedrooms\": [1, 2],\n",
    "        \"bathrooms\": [1, 2],\n",
    "        \"MALL\": 1,\n",
    "        \"MARKET\": 1,\n",
    "        \"TRANSPORT\": 1\n",
    "    }\n",
    "}\n",
    "\n",
    "# Helper function to calculate match score\n",
    "def match_score(property_row, persona_criteria):\n",
    "    matches = 0\n",
    "    total = 0\n",
    "\n",
    "    for key, val in persona_criteria.items():\n",
    "        if key in ['land_area', 'building_area']:\n",
    "            if not pd.isna(property_row[key]):\n",
    "                if val[0] <= property_row[key] <= val[1]:\n",
    "                    matches += 1\n",
    "            total += 1\n",
    "        elif key in ['bedrooms', 'bathrooms']:\n",
    "            try:\n",
    "                if int(property_row[key]) in val:\n",
    "                    matches += 1\n",
    "            except:\n",
    "                pass\n",
    "            total += 1\n",
    "        elif key == 'type':\n",
    "            if isinstance(val, list):\n",
    "                if isinstance(property_row[key], str) and property_row[key].lower() in [v.lower() for v in val]:\n",
    "                    matches += 1\n",
    "            else:\n",
    "                if isinstance(property_row[key], str) and property_row[key].lower() == val.lower():\n",
    "                    matches += 1\n",
    "            total += 1\n",
    "\n",
    "    return matches / total if total > 0 else 0\n",
    "\n",
    "# Score each property\n",
    "persona_scores = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    scores = {persona: match_score(row, criteria) for persona, criteria in ideal_personas.items()}\n",
    "    best_match = max(scores, key=scores.get)\n",
    "\n",
    "    # Extract main attributes\n",
    "    property_data = {\n",
    "        \"title\": row.get(\"title\", \"\"),\n",
    "        \"best_persona_match\": best_match,\n",
    "        \"match_score\": scores[best_match],\n",
    "        \"type\": row.get(\"type\"),\n",
    "        \"land_area\": row.get(\"land_area\"),\n",
    "        \"building_area\": row.get(\"building_area\"),\n",
    "        \"bedrooms\": row.get(\"bedrooms\"),\n",
    "        \"bathrooms\": row.get(\"bathrooms\"),\n",
    "        \"floors\": row.get(\"floors\"),\n",
    "        \n",
    "    }\n",
    "\n",
    "    # Optionally include all entity columns dynamically (assuming they are binary flags like SCHOOL, HOSPITAL, etc.)\n",
    "    entity_cols = [\"SCHOOL\", \"HOSPITAL\", \"TRANSPORT\", \"MARKET\", \"MALL\"]\n",
    "    for col in entity_cols:\n",
    "        property_data[col] = row.get(col)\n",
    "\n",
    "    persona_scores.append(property_data)\n",
    "\n",
    "# Create DataFrame with results\n",
    "persona_score_df = pd.DataFrame(persona_scores)\n",
    "\n",
    "# Save to CSV (optional)  \n",
    "filepath = Path('KBRS/kbrs_dataset.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "persona_score_df.to_csv(filepath)\n",
    "\n",
    "# Preview\n",
    "print(persona_score_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571e8a96",
   "metadata": {},
   "source": [
    "# Personalized CBRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2c8425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load dataset ===\n",
    "df = pd.read_csv(\"KBRS/kbrs_dataset.csv\")\n",
    "\n",
    "# === USER INPUT ===\n",
    "user_input = {\n",
    "    \"Persona\": \"Pasangan Bekerja tanpa Anak\",\n",
    "    \"type\": \"Rumah\",\n",
    "    \"land_area\": 200,\n",
    "    \"building_area\": 50,\n",
    "    \"bedrooms\": 2,\n",
    "    \"bathrooms\": 2,\n",
    "    \"floors\": 2,\n",
    "    \"SCHOOL\": 0,\n",
    "    \"HOSPITAL\": 1,\n",
    "    \"TRANSPORT\": 1,\n",
    "    \"MARKET\": 0,\n",
    "    \"MALL\": 1\n",
    "}\n",
    "\n",
    "# === Filter dataset by persona ===\n",
    "persona = user_input['Persona']\n",
    "filtered_df = df[df['best_persona_match'] == persona].copy()\n",
    "\n",
    "# === Select relevant structured features ===\n",
    "features = ['type', 'land_area', 'building_area', 'bedrooms', 'bathrooms', 'floors',\n",
    "            'SCHOOL', 'HOSPITAL', 'TRANSPORT', 'MARKET', 'MALL']\n",
    "\n",
    "# === Prepare dataset features ===\n",
    "filtered_df_structured = filtered_df[features].copy()\n",
    "\n",
    "# Handle categorical encoding (for 'type')\n",
    "categorical_cols = ['type']\n",
    "numeric_cols = [col for col in features if col not in categorical_cols]\n",
    "\n",
    "# One-hot encode 'type'\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "encoded_types = encoder.fit_transform(filtered_df_structured[categorical_cols])\n",
    "encoded_type_cols = encoder.get_feature_names_out(categorical_cols)\n",
    "\n",
    "def clean_numeric_column(series):\n",
    "    return (\n",
    "        series.replace('>10', 10)\n",
    "              .replace('3+', 3)\n",
    "              .replace('2+', 2)\n",
    "              .replace('4+', 4)\n",
    "              .replace('-', np.nan)\n",
    "              .astype(float)\n",
    "    )\n",
    "\n",
    "# Clean numeric columns\n",
    "for col in numeric_cols:\n",
    "    filtered_df[col] = clean_numeric_column(filtered_df[col])\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = MinMaxScaler()\n",
    "scaled_numeric = scaler.fit_transform(filtered_df[numeric_cols])\n",
    "scaled_numeric_df = pd.DataFrame(scaled_numeric, columns=numeric_cols)\n",
    "\n",
    "# Combine encoded + scaled features\n",
    "property_matrix = hstack([csr_matrix(encoded_types), csr_matrix(scaled_numeric)])\n",
    "\n",
    "# === Prepare user input vector ===\n",
    "user_df = pd.DataFrame([user_input])\n",
    "user_structured = user_df[features].copy()\n",
    "\n",
    "# Encode 'type'\n",
    "user_encoded_type = encoder.transform(user_structured[categorical_cols])\n",
    "# Scale numeric\n",
    "user_scaled_numeric = scaler.transform(user_structured[numeric_cols])\n",
    "\n",
    "# Combine user features\n",
    "user_vector = hstack([csr_matrix(user_encoded_type), csr_matrix(user_scaled_numeric)])\n",
    "\n",
    "# === Compute Cosine Similarity ===\n",
    "similarity_scores = cosine_similarity(user_vector, property_matrix)[0]\n",
    "\n",
    "# === Top N Results ===\n",
    "top_n = 10\n",
    "top_indices = np.argsort(similarity_scores)[::-1][:top_n]\n",
    "recommended = filtered_df.iloc[top_indices].copy()\n",
    "recommended['similarity_score'] = similarity_scores[top_indices]\n",
    "\n",
    "# === Output ===\n",
    "print(\"\\nTop Recommendations for Persona:\", persona)\n",
    "print(recommended[['title', 'type', 'bedrooms', 'bathrooms', 'similarity_score']])\n",
    "\n",
    "# === Save to CSV ===\n",
    "filepath = Path('CBRS/cbrs_results.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "recommended.to_csv(filepath, index=False)\n",
    "print(\"\\nâœ… Top-N recommendations saved to 'cbrs_results.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90ae3c1",
   "metadata": {},
   "source": [
    "# SPK with Profile Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f631d468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Top-N CBRS results\n",
    "df = pd.read_csv(\"CBRS/cbrs_results.csv\")\n",
    "\n",
    "# Ideal profile based on user input\n",
    "ideal_profile = {\n",
    "    \"type\": \"Rumah\",\n",
    "    \"land_area\": 200,\n",
    "    \"building_area\": 50,\n",
    "    \"bedrooms\": 2,\n",
    "    \"bathrooms\": 2,\n",
    "    \"floors\": 2,\n",
    "    \"SCHOOL\": 0,\n",
    "    \"HOSPITAL\": 1,\n",
    "    \"TRANSPORT\": 1,\n",
    "    \"MARKET\": 0,\n",
    "    \"MALL\": 1\n",
    "}\n",
    "\n",
    "# Bobot kriteria (bisa disesuaikan)\n",
    "weights = {\n",
    "    \"type\": 5,\n",
    "    \"land_area\": 4,\n",
    "    \"building_area\": 4,\n",
    "    \"bedrooms\": 3,\n",
    "    \"bathrooms\": 3,\n",
    "    \"floors\": 2,\n",
    "    \"SCHOOL\": 2,\n",
    "    \"HOSPITAL\": 3,\n",
    "    \"TRANSPORT\": 3,\n",
    "    \"MARKET\": 2,\n",
    "    \"MALL\": 3\n",
    "}\n",
    "\n",
    "# Skala konversi gap (selisih -> nilai skor)\n",
    "def gap_to_score(gap):\n",
    "    if gap == 0:\n",
    "        return 5\n",
    "    elif gap == 1 or gap == -1:\n",
    "        return 4.5\n",
    "    elif gap == 2 or gap == -2:\n",
    "        return 4\n",
    "    elif gap == 3 or gap == -3:\n",
    "        return 3.5\n",
    "    elif gap == 4 or gap == -4:\n",
    "        return 3\n",
    "    elif gap >= 5 or gap <= -5:\n",
    "        return 2.5\n",
    "    else:\n",
    "        return 1  # fallback\n",
    "\n",
    "# Fungsi menghitung total score untuk setiap properti\n",
    "def calculate_total_score(row):\n",
    "    total_score = 0\n",
    "    total_weight = 0\n",
    "    for key in ideal_profile:\n",
    "        if key == \"type\":\n",
    "            score = 5 if row[key].lower() == ideal_profile[key].lower() else 1\n",
    "        else:\n",
    "            try:\n",
    "                gap = row[key] - ideal_profile[key]\n",
    "                score = gap_to_score(gap)\n",
    "            except:\n",
    "                score = 1  # jika data kosong atau tidak valid\n",
    "        total_score += score * weights[key]\n",
    "        total_weight += weights[key]\n",
    "    return total_score / total_weight if total_weight else 0\n",
    "\n",
    "# Hitung skor untuk semua properti\n",
    "df[\"gap_score\"] = df.apply(calculate_total_score, axis=1)\n",
    "\n",
    "# Urutkan berdasarkan skor tertinggi\n",
    "df_sorted = df.sort_values(by=\"gap_score\", ascending=False)\n",
    "\n",
    "# Simpan hasilnya\n",
    "df_sorted.to_csv(\"final_profile_matching_result.csv\", index=False)\n",
    "\n",
    "# Tampilkan hasil teratas\n",
    "df_sorted[[\"title\", \"type\", \"bedrooms\", \"bathrooms\", \"similarity_score\", \"gap_score\"]].head(5)\n",
    "\n",
    "# === Output ===\n",
    "print(\"\\nRecommended Properties\")\n",
    "print(df_sorted[[\"title\", \"type\", \"bedrooms\", \"bathrooms\", \"similarity_score\", \"gap_score\"]])\n",
    "\n",
    "# Save the final DataFrame to CSV\n",
    "filepath = Path('profile_matching/hasil_akhir.csv')\n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_sorted.to_csv(filepath, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
